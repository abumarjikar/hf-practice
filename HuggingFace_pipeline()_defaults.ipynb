{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace_pipeline()_defaults.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNL5BNVC08I7BlKyimC3I5K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abumarjikar/hf-practice/blob/main/HuggingFace_pipeline()_defaults.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY_kgbXWdQL8",
        "outputId": "c42f2351-2456-4ff5-fe6c-975417ee402e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9997630715370178},\n",
              " {'label': 'POSITIVE', 'score': 0.9958556294441223}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier([\"Today i am not feeling well.\",\"I am glad that i am learning huggingface.\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = pipeline(\"feature-extraction\")\n",
        "feature_extractor(\"I love my India.\")"
      ],
      "metadata": {
        "id": "pB4WkAOuixc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neR = pipeline(\"ner\")\n",
        "neR(\"I love India, I am CEO of Facebook.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CosMOKBAjkWP",
        "outputId": "b9438434-fea2-42c9-d3b2-e335d8f6e93d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 12,\n",
              "  'entity': 'I-LOC',\n",
              "  'index': 3,\n",
              "  'score': 0.9996457,\n",
              "  'start': 7,\n",
              "  'word': 'India'},\n",
              " {'end': 34,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 9,\n",
              "  'score': 0.9987054,\n",
              "  'start': 26,\n",
              "  'word': 'Facebook'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is my india and india is my country.\",\n",
        "    candidate_labels=[\"Emotional\", \"National\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIQljLXIj6XD",
        "outputId": "aefd7259-5348-4129-ad75-e9365a88987e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': ['National', 'Emotional'],\n",
              " 'scores': [0.5570379495620728, 0.44296208024024963],\n",
              " 'sequence': 'This is my india and india is my country.'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_generator = pipeline(\"text-generation\")\n",
        "text_generator(\n",
        "    \"I love India because\",\n",
        "    num_return_sequences=2,\n",
        "    max_length =20\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DruMdlonaAl",
        "outputId": "16b9f149-ca86-4e68-aa73-1863b3c9859f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'I love India because the country is so clean,\" he said.\\n\\nWith the Indian Ministry of'},\n",
              " {'generated_text': 'I love India because of the love of India,\" said Pradhan, the former general secretary of'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}